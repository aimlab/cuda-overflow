



## 总结
- 总的来说memory共享符合cuda的设计（local/shared/grid），但是在两个kernel中，一个申请的shared memory在另外一个kernel中居然可以使用！！


## 方法论
- 测试memory是否共享，申请一个堆，并且赋值，看其他的thread/block/grid中能否使用
- 测试堆是否在thread/block/grid之间相互影响，申请多个堆，赋值一个，并使这一个溢出，在其他堆中查看数据是否存在

> 这个溢出有时候不会覆盖objD：因为运行的顺序问题，所以即使覆盖了，接下来的thread/block/grid可以覆盖回来，特别是kernel的运行是串行的。






- 单个堆的共享情况和危害程度，memory共享情况符合cuda状况
> 一个线程来进行初始化堆，控制只有一个线程输入
> 不让第一个线程直接free（）释放了buf使后面的线程使用不了
> 总的来说memory共享符合cuda的设计（local/shared/grid），但是在两个kernel中，一个申请的shared memory在另外一个kernel中居然可以使用！！

- 上次堆里面使用的数据会保存下来，不会自动清除，但是可以覆盖
> 用来确定堆中的数据是否会保留，更改man（）中的i和len的值，是len减小发现旧的i的值保留在len（旧）-len（新）中

- 选择一个具体的内存架构实例来说明：第二个溢出的是第一个obj，因为堆的内存是相邻的，第二个buf可以控制第一个，第一个能控制第二个,线程之间buf覆盖有不确定性，当其中一个越界，另外一个不越界时，好控制溢出攻击
> 通过控制第二个堆的写入来溢出第一个和第二个，以及第一个堆的写入比平常更大的buf来溢出第一个和第二个
> 由实例推出总结:不管在哪个级别（thread/block/grid）申请的堆都是叠放在一起统一进行管理的，可以相互覆盖

- 串行两个kernel之间的相互影响
> 用来确定是否相互影响，只赋值一个，看另外一个kernel的heap里面的值会不会改变，两个kernel之间是串行执行的，所以赋值得赋值第一个kernel(kernel的确定通过一个kernel两线程，一个kernel一个线程)：heap之间可以想通，但是因为第二个kernel的objD可以再次修复，所以不一定能溢出（通过选择性赋值来避免再次修复）
- 并发的两个kernel之间的相互影响
> -可以实现多个kernel之间的并行，但是跟计算单元队列数有关，如果只有一个计算单元的话，实现的并发也只是数据在device host 数据拷贝的并发
> 根据代码执行的时间来造成堆位置的不确定性，通过插入睡眠可以做到第一个控制第二个kernel

